{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# Lab 1.3 â€“ Debug Challenge: OpenCV Pipeline & Kernel Design\n",
    "### Module 3: Computer Vision and Image Processing | B.Tech AI Specialisation\n",
    "**Chitkara University | Day 1**\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook contains a complete **image processing pipeline** built using OpenCV.  \n",
    "The pipeline reads an image, applies a series of filters and transformations, detects edges, and draws contours.\n",
    "\n",
    "**The problem:** A classmate wrote this pipeline the night before the lab, ran it once, and it seemed fine.  \n",
    "But when reviewed carefully, **5 bugs were found** â€” some cause wrong output, some cause crashes, and one is a logic error that gives plausible-but-incorrect results.\n",
    "\n",
    "## Your Task\n",
    "\n",
    "- Read through each section of the pipeline carefully\n",
    "- Run each cell and observe the output (errors, warnings, or wrong images)\n",
    "- **Find all 5 bugs**, understand why each one is wrong, and fix it\n",
    "- Fill in the answer cells below each section\n",
    "\n",
    "## Rules\n",
    "\n",
    "- Do **not** jump to the answer key at the bottom until you've attempted each bug\n",
    "- Each bug is in a **different section** â€” one bug per section\n",
    "- Bugs range from simple typos to logical mistakes â€” read the code, don't just run it\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Stages\n",
    "\n",
    "| Stage | Operation | Section |\n",
    "|-------|-----------|--------|\n",
    "| 1 | Image Loading & Color Conversion | Bug 1 |\n",
    "| 2 | Custom Kernel Design & Convolution | Bug 2 |\n",
    "| 3 | Gaussian Blur & Thresholding | Bug 3 |\n",
    "| 4 | Edge Detection (Canny) | Bug 4 |\n",
    "| 5 | Contour Detection & Drawing | Bug 5 |\n",
    "\n",
    "---\n",
    "\n",
    "> **Tip:** Before running a cell, read it first. Ask yourself: *\"What should this output?\"*  \n",
    "> Then run it and compare with what you expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-setup-header",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run this cell first. It installs dependencies and creates a sample test image so you don't need any external files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell first â€” sets up everything you need\n",
    "import subprocess, sys\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', 'opencv-python-headless', 'matplotlib', 'numpy'], \n",
    "               capture_output=True)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (14, 5)\n",
    "\n",
    "# â”€â”€ Helper: display images side by side â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def show(images, titles, cmap_list=None):\n",
    "    \"\"\"Display a list of images with titles in a row.\"\"\"\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(5 * n, 5))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for ax, img, title, cmap in zip(axes, images, titles,\n",
    "                                     cmap_list or ['gray'] * n):\n",
    "        ax.imshow(img, cmap=cmap)\n",
    "        ax.set_title(title, fontsize=12)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# â”€â”€ Create a synthetic test image â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# A 300x300 BGR image: white background, a black rectangle, a filled circle\n",
    "test_img = np.ones((300, 300, 3), dtype=np.uint8) * 200   # light-gray background\n",
    "cv2.rectangle(test_img, (30, 30), (130, 130), (20, 20, 20), -1)   # dark square\n",
    "cv2.circle(test_img,   (220, 80),  50,         (20, 20, 20), -1)   # dark circle\n",
    "cv2.rectangle(test_img, (60, 170), (250, 270), (20, 20, 20), 3)    # hollow rect\n",
    "cv2.imwrite('test_image.png', test_img)\n",
    "\n",
    "print('Setup complete.')\n",
    "print('OpenCV version :', cv2.__version__)\n",
    "print('Test image saved as test_image.png  (300 x 300 px, 3 channels)')\n",
    "show([cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)], ['Test Image (ground truth)'], ['viridis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1 â€” Image Loading & Color Space Conversion\n",
    "\n",
    "**What this section should do:**\n",
    "1. Load `test_image.png` from disk using OpenCV\n",
    "2. Convert the loaded BGR image to **RGB** so matplotlib displays it correctly\n",
    "3. Convert the RGB image to **Grayscale** for downstream processing\n",
    "4. Display all three versions side-by-side\n",
    "\n",
    "**Expected result:** The RGB image should look natural (gray background, dark shapes).  \n",
    "The grayscale image should be a single-channel version of the same scene.\n",
    "\n",
    "> **Hint:** OpenCV loads images in **BGR** order, not RGB. Pay attention to which conversion code is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s1-buggy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ SECTION 1: Image Loading & Color Conversion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Load image from disk\n",
    "bgr_image = cv2.imread('test_image.png')\n",
    "\n",
    "if bgr_image is None:\n",
    "    raise FileNotFoundError('test_image.png not found â€” did you run the Setup cell?')\n",
    "\n",
    "print('Image shape (H, W, C):', bgr_image.shape)\n",
    "print('Data type            :', bgr_image.dtype)\n",
    "\n",
    "# Convert BGR â†’ RGB for correct matplotlib display\n",
    "# BUG 1 is somewhere in these two conversion lines\n",
    "rgb_image  = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)   # Convert to display format\n",
    "gray_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)   # Convert to grayscale\n",
    "\n",
    "show(\n",
    "    [bgr_image, rgb_image, gray_image],\n",
    "    ['Loaded (BGR â€” matplotlib reads wrong)', 'After Conversion', 'Grayscale'],\n",
    "    [None, None, 'gray']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-answer",
   "metadata": {},
   "source": [
    "### ðŸ” Your Answer â€“ Bug 1\n",
    "\n",
    "**Line number where the bug is:** `____`\n",
    "\n",
    "**What is wrong:**\n",
    "\n",
    "```\n",
    "Write your explanation here.\n",
    "```\n",
    "\n",
    "**Fixed code:**\n",
    "\n",
    "```python\n",
    "# Paste your corrected line(s) here\n",
    "```\n",
    "\n",
    "**Why does this matter in a real pipeline?**\n",
    "\n",
    "```\n",
    "Write your reasoning here.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2 â€” Custom Kernel Design & Convolution\n",
    "\n",
    "**What this section should do:**\n",
    "1. Define a **3Ã—3 sharpening kernel** that enhances edges while keeping brightness stable\n",
    "2. Define a **3Ã—3 box blur kernel** that averages all 9 neighbouring pixels equally\n",
    "3. Apply both kernels to the grayscale image using `cv2.filter2D`\n",
    "4. Display original, sharpened, and blurred images\n",
    "\n",
    "**Background â€” Kernel Rules:**\n",
    "\n",
    "| Kernel Type | Centre Value | Neighbours | Sum of all values |\n",
    "|-------------|-------------|------------|-------------------|\n",
    "| Identity | 1 | 0 | 1 |\n",
    "| Box blur (3Ã—3) | 1/9 | 1/9 each | 1 |\n",
    "| Sharpening | 5 | âˆ’1 at 4 sides, 0 corners | **1** |\n",
    "\n",
    "A sharpening kernel that doesn't sum to 1 will change the **overall brightness** of the image.\n",
    "\n",
    "> **Hint:** Count the values in the sharpening kernel carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-buggy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ SECTION 2: Custom Kernel Design & Convolution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# â”€â”€ Fix Bug 1 first â€” use a correct gray_image before running this cell â”€â”€\n",
    "# For now, reload gray safely:\n",
    "bgr_image  = cv2.imread('test_image.png')\n",
    "gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Sharpening kernel â€” enhances edges, preserves overall brightness\n",
    "# BUG 2 is in the kernel definition below\n",
    "sharpen_kernel = np.array([\n",
    "    [ 0, -1,  0],\n",
    "    [-1,  4, -1],   # <-- look carefully at the centre value\n",
    "    [ 0, -1,  0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Box blur kernel â€” each pixel becomes the average of its 3x3 neighbourhood\n",
    "box_blur_kernel = np.ones((3, 3), dtype=np.float32) / 9\n",
    "\n",
    "# Print kernel properties\n",
    "print('Sharpening kernel:')\n",
    "print(sharpen_kernel)\n",
    "print('Sum of sharpening kernel:', sharpen_kernel.sum())   # Should be 1\n",
    "print()\n",
    "print('Box blur kernel:')\n",
    "print(np.round(box_blur_kernel, 3))\n",
    "print('Sum of box blur kernel  :', box_blur_kernel.sum())  # Should be 1\n",
    "\n",
    "# Apply kernels\n",
    "sharpened = cv2.filter2D(gray_image, -1, sharpen_kernel)\n",
    "blurred   = cv2.filter2D(gray_image, -1, box_blur_kernel)\n",
    "\n",
    "show(\n",
    "    [gray_image, sharpened, blurred],\n",
    "    ['Original Grayscale', 'Sharpened (custom kernel)', 'Box Blur (custom kernel)'],\n",
    "    ['gray', 'gray', 'gray']\n",
    ")\n",
    "\n",
    "print('\\nObserve: Does the sharpened image look brighter or darker than the original?')\n",
    "print('Mean pixel value â€” original :', gray_image.mean().round(2))\n",
    "print('Mean pixel value â€” sharpened:', sharpened.mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-answer",
   "metadata": {},
   "source": [
    "### ðŸ” Your Answer â€“ Bug 2\n",
    "\n",
    "**What is wrong with the sharpening kernel:**\n",
    "\n",
    "```\n",
    "Write your explanation here. Show the correct kernel values.\n",
    "```\n",
    "\n",
    "**Fixed kernel:**\n",
    "\n",
    "```python\n",
    "sharpen_kernel = np.array([\n",
    "    # your corrected values\n",
    "], dtype=np.float32)\n",
    "```\n",
    "\n",
    "**What visual effect does the wrong kernel produce vs the correct one?**\n",
    "\n",
    "```\n",
    "Write your answer here.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3 â€” Gaussian Blur & Binary Thresholding\n",
    "\n",
    "**What this section should do:**\n",
    "1. Apply **Gaussian blur** to the grayscale image to reduce noise before edge detection\n",
    "2. Apply **binary threshold** to separate foreground (dark shapes) from background\n",
    "3. Display blurred and thresholded results\n",
    "\n",
    "**Background â€” Gaussian Blur:**\n",
    "- `cv2.GaussianBlur(src, ksize, sigmaX)`\n",
    "- `ksize` is a **tuple** representing kernel height and width\n",
    "- Both values in `ksize` **must be odd positive integers**: 1, 3, 5, 7, ...\n",
    "- An even kernel size will raise a hard error\n",
    "\n",
    "> **Hint:** Run this cell and read the error message carefully. The fix is a one-character change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-buggy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ SECTION 3: Gaussian Blur & Binary Thresholding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "bgr_image  = cv2.imread('test_image.png')\n",
    "gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur to smooth the image before edge detection\n",
    "# sigmaX=0 tells OpenCV to calculate sigma automatically from kernel size\n",
    "# BUG 3 is in the line below\n",
    "blurred = cv2.GaussianBlur(gray_image, (4, 4), sigmaX=0)\n",
    "\n",
    "# Binary threshold: pixels below 150 â†’ 0 (black), pixels above â†’ 255 (white)\n",
    "# THRESH_BINARY_INV inverts this: dark shapes become white in the mask\n",
    "_, thresh = cv2.threshold(blurred, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "show(\n",
    "    [gray_image, blurred, thresh],\n",
    "    ['Original Grayscale', 'Gaussian Blurred (5x5)', 'Binary Threshold (inv)'],\n",
    "    ['gray', 'gray', 'gray']\n",
    ")\n",
    "\n",
    "print('Blurred image shape :', blurred.shape)\n",
    "print('Threshold unique values:', np.unique(thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-answer",
   "metadata": {},
   "source": [
    "### ðŸ” Your Answer â€“ Bug 3\n",
    "\n",
    "**What is wrong and why does OpenCV require it to be different:**\n",
    "\n",
    "```\n",
    "Write your explanation here.\n",
    "```\n",
    "\n",
    "**Fixed line:**\n",
    "\n",
    "```python\n",
    "blurred = cv2.GaussianBlur(...)   # corrected\n",
    "```\n",
    "\n",
    "**Bonus question:** What happens if you make the kernel size very large (e.g., 51Ã—51)?  \n",
    "Would that help or hurt edge detection in the next stage?\n",
    "\n",
    "```\n",
    "Your answer:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4 â€” Canny Edge Detection\n",
    "\n",
    "**What this section should do:**\n",
    "1. Apply Canny edge detection on the blurred grayscale image\n",
    "2. Experiment with threshold values\n",
    "3. Display the detected edges\n",
    "\n",
    "**Background â€” Canny Thresholds:**\n",
    "\n",
    "The Canny algorithm uses **two thresholds**:\n",
    "- `threshold1` (lower) â€” Edges weaker than this are **discarded**\n",
    "- `threshold2` (upper) â€” Edges stronger than this are **definitely kept**\n",
    "- Edges between the two values are kept only if they **connect to a strong edge**\n",
    "\n",
    "**Rule:** `threshold1` must always be **less than** `threshold2`.\n",
    "\n",
    "Swapping them does not raise an error â€” it silently produces bad output.  \n",
    "This is the trickiest kind of bug: it runs fine but gives wrong results.\n",
    "\n",
    "> **Hint:** Run the cell. The edge map will look unusually sparse or noisy. Compare the two threshold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-buggy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ SECTION 4: Canny Edge Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "bgr_image  = cv2.imread('test_image.png')\n",
    "gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "blurred    = cv2.GaussianBlur(gray_image, (5, 5), sigmaX=0)   # fixed from Section 3\n",
    "\n",
    "# Apply Canny edge detection\n",
    "# cv2.Canny(image, threshold1, threshold2)\n",
    "# BUG 4: The threshold values below are swapped\n",
    "edges = cv2.Canny(blurred, threshold1=200, threshold2=50)\n",
    "\n",
    "# Also run a correct version for visual comparison (don't modify this)\n",
    "edges_reference = cv2.Canny(blurred, threshold1=50, threshold2=150)\n",
    "\n",
    "show(\n",
    "    [blurred, edges, edges_reference],\n",
    "    ['Blurred Input', 'Edges (current code)', 'Edges (reference â€” 50, 150)'],\n",
    "    ['gray', 'gray', 'gray']\n",
    ")\n",
    "\n",
    "print('Edge pixels detected (current code)  :', np.count_nonzero(edges))\n",
    "print('Edge pixels detected (reference code):', np.count_nonzero(edges_reference))\n",
    "print()\n",
    "print('A good Canny result should detect the clean outlines of')\n",
    "print('the rectangle, circle, and hollow rectangle in the image.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-answer",
   "metadata": {},
   "source": [
    "### ðŸ” Your Answer â€“ Bug 4\n",
    "\n",
    "**What is wrong:**\n",
    "\n",
    "```\n",
    "Write your explanation here.\n",
    "```\n",
    "\n",
    "**Fixed line:**\n",
    "\n",
    "```python\n",
    "edges = cv2.Canny(...)   # corrected\n",
    "```\n",
    "\n",
    "**Why is this a dangerous type of bug compared to the others?**\n",
    "\n",
    "```\n",
    "Hint: think about when bugs are caught and what damage they can cause silently.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5 â€” Contour Detection & Drawing\n",
    "\n",
    "**What this section should do:**\n",
    "1. Find contours in the binary threshold image from Section 3\n",
    "2. Filter out tiny contours (noise) by area\n",
    "3. Draw the detected contours on a copy of the original image in **green**\n",
    "4. Print how many valid shapes were found\n",
    "\n",
    "**Background â€” Contour Retrieval Modes:**\n",
    "\n",
    "| Flag | Meaning | Use when |\n",
    "|------|---------|----------|\n",
    "| `cv2.RETR_EXTERNAL` | Retrieves only **outermost** contours | You want the bounding shapes only |\n",
    "| `cv2.RETR_LIST` | Retrieves all contours, **no hierarchy** | You want every contour individually |\n",
    "| `cv2.RETR_TREE` | Retrieves all contours with **full hierarchy** | You need nested parent-child info |\n",
    "\n",
    "The test image has a **hollow rectangle** (a border drawn with `cv2.rectangle(..., thickness=3)`).  \n",
    "This creates an **outer contour** and potentially an **inner contour**.  \n",
    "Using the wrong retrieval mode can return the wrong number of contours or miss shapes entirely.\n",
    "\n",
    "> **Hint:** The code uses `cv2.RETR_TREE` and then tries to index the result as if only a simple list was returned â€” the unpacking is mismatched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s5-buggy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ SECTION 5: Contour Detection & Drawing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "bgr_image  = cv2.imread('test_image.png')\n",
    "gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "blurred    = cv2.GaussianBlur(gray_image, (5, 5), sigmaX=0)\n",
    "_, thresh  = cv2.threshold(blurred, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours in the threshold image\n",
    "# cv2.findContours returns: (contours, hierarchy)\n",
    "# BUG 5: the retrieval mode and the unpacking do not match the intended goal\n",
    "contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter: keep only contours with area > 300 pixels (removes noise)\n",
    "min_area = 300\n",
    "valid_contours = [c for c in contours if cv2.contourArea(c) > min_area]\n",
    "\n",
    "print(f'Total contours found : {len(contours)}')\n",
    "print(f'Valid contours (area > {min_area}): {len(valid_contours)}')\n",
    "\n",
    "# Draw contours on a copy of the original image\n",
    "output = bgr_image.copy()\n",
    "cv2.drawContours(output, valid_contours, -1, (0, 255, 0), 2)   # green, thickness=2\n",
    "output_rgb = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "show(\n",
    "    [thresh, output_rgb],\n",
    "    ['Threshold Mask', f'Detected Contours ({len(valid_contours)} shapes in green)'],\n",
    "    ['gray', None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-answer",
   "metadata": {},
   "source": [
    "### ðŸ” Your Answer â€“ Bug 5\n",
    "\n",
    "**What is wrong:**\n",
    "\n",
    "```\n",
    "Write your explanation here. What does cv2.findContours actually return?\n",
    "How should the result be unpacked correctly?\n",
    "```\n",
    "\n",
    "**Fixed lines:**\n",
    "\n",
    "```python\n",
    "contours, hierarchy = cv2.findContours(...)   # corrected unpacking\n",
    "```\n",
    "\n",
    "**Also answer:** What retrieval mode is most appropriate here and why?\n",
    "\n",
    "```\n",
    "Your answer:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-full-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Full Corrected Pipeline\n",
    "\n",
    "Once you have identified and fixed all 5 bugs, write the complete corrected pipeline in the cell below.  \n",
    "All 5 sections should run together without errors and produce clean, correct output.\n",
    "\n",
    "**Expected output:**\n",
    "- RGB image displays correctly (natural gray-background image)\n",
    "- Sharpened image has the same brightness as the original (mean pixel values are close)\n",
    "- Gaussian blur runs without error\n",
    "- Canny edges cleanly trace the shapes (rectangle outline, circle outline, hollow rectangle)\n",
    "- Contour detection finds **3 valid shapes** and draws green borders around them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-full-corrected",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ FULL CORRECTED PIPELINE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Write your corrected version of all 5 sections here.\n",
    "# Each fix should be clearly marked with a comment: # FIX 1, # FIX 2, etc.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show(images, titles, cmap_list=None):\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(5 * n, 5))\n",
    "    if n == 1: axes = [axes]\n",
    "    for ax, img, title, cmap in zip(axes, images, titles, cmap_list or ['gray'] * n):\n",
    "        ax.imshow(img, cmap=cmap)\n",
    "        ax.set_title(title, fontsize=12)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# â”€â”€ Stage 1: Load & Convert â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "bgr_image  = cv2.imread('test_image.png')\n",
    "rgb_image  = ...  # FIX 1: replace the conversion code here\n",
    "gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# â”€â”€ Stage 2: Custom Kernels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sharpen_kernel = np.array([   # FIX 2: correct the kernel values\n",
    "    [ 0, -1,  0],\n",
    "    [-1,  ?,  -1],\n",
    "    [ 0, -1,  0]\n",
    "], dtype=np.float32)\n",
    "box_blur_kernel = np.ones((3, 3), dtype=np.float32) / 9\n",
    "sharpened = cv2.filter2D(gray_image, -1, sharpen_kernel)\n",
    "blurred_box = cv2.filter2D(gray_image, -1, box_blur_kernel)\n",
    "\n",
    "# â”€â”€ Stage 3: Gaussian Blur & Threshold â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "blurred = cv2.GaussianBlur(gray_image, ..., sigmaX=0)   # FIX 3: correct ksize\n",
    "_, thresh = cv2.threshold(blurred, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# â”€â”€ Stage 4: Canny Edge Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "edges = cv2.Canny(blurred, threshold1=..., threshold2=...)  # FIX 4: correct order\n",
    "\n",
    "# â”€â”€ Stage 5: Contour Detection & Drawing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "contours, hierarchy = cv2.findContours(...)  # FIX 5: correct unpacking and mode\n",
    "valid_contours = [c for c in contours if cv2.contourArea(c) > 300]\n",
    "output = bgr_image.copy()\n",
    "cv2.drawContours(output, valid_contours, -1, (0, 255, 0), 2)\n",
    "output_rgb = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# â”€â”€ Final Display â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "show(\n",
    "    [rgb_image, gray_image, sharpened, blurred, edges, output_rgb],\n",
    "    ['RGB', 'Grayscale', 'Sharpened', 'Blurred', 'Edges (Canny)',\n",
    "     f'Contours ({len(valid_contours)} shapes)'],\n",
    "    [None, 'gray', 'gray', 'gray', 'gray', None]\n",
    ")\n",
    "\n",
    "print('Pipeline complete.')\n",
    "print(f'Shapes found: {len(valid_contours)} (expected: 3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-extension",
   "metadata": {},
   "source": [
    "---\n",
    "## Extension Challenges (Optional â€” for fast finishers)\n",
    "\n",
    "If you finish early, try these additional tasks:\n",
    "\n",
    "### Challenge A â€” Kernel Experimentation\n",
    "Design your own **emboss kernel** that makes the image look like it has a raised 3D surface.  \n",
    "Hint: An emboss kernel shifts light from one direction.\n",
    "\n",
    "```python\n",
    "emboss_kernel = np.array([\n",
    "    [-2, -1,  0],\n",
    "    [-1,  1,  1],\n",
    "    [ 0,  1,  2]\n",
    "], dtype=np.float32)\n",
    "# Try applying this and add 128 to the result to centre the values\n",
    "embossed = cv2.filter2D(gray_image, -1, emboss_kernel) + 128\n",
    "```\n",
    "\n",
    "### Challenge B â€” Contour Properties\n",
    "For each valid contour detected in Section 5, compute and print:\n",
    "- Area (pixelsÂ²)\n",
    "- Perimeter\n",
    "- Bounding box (x, y, w, h)\n",
    "- Shape label: 'circle', 'rectangle', or 'other' based on the ratio of area to bounding box area\n",
    "\n",
    "### Challenge C â€” Pipeline on a Real Image\n",
    "Find any `.jpg` or `.png` image on your laptop.  \n",
    "Run the full corrected pipeline on it.  \n",
    "Does the Canny threshold you used still work well? Why or why not?  \n",
    "What would you need to change for a more complex, real-world image?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
